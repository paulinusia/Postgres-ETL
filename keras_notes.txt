Summary of seq2seq process using keras:

 encoder data (the pattern/strucutre of the data is extracted from encoder)

 1. Turn sentences into 3 numpy arrays:
  encoder_input- 3D array of shape (num_pairs, max_input sentence lengh, num characters)
  decoder_input- 3D array of of shape (num of pairs, max output reply length, number of characters)
  decoder_target_data- same as decoder_input but offset by one timestep.

  2. Train LSTM- seq 2 seq to predict decoder_target_data given encoder and decoder using teacher forcing

  3. Decode sentences



  
